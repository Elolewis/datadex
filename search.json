[
  {
    "objectID": "docs/tutorial.html",
    "href": "docs/tutorial.html",
    "title": "Datadex Tutorial",
    "section": "",
    "text": "Let’s ingest and model some open data. We’ll cover all the basics to get you started with Datadex. If you’re not familiar with dbt or Dagster, I recommend you to check their tutorials to get a sense of how these tools work.\n\n\nThe first thing is to add your desired dataset to Datadex. To do that, you’ll need to create a new Dagster Asset in assets.py. You’ll need to write a Python function that returns a DataFrame. You can do anything and read from anywhere as long as you return a DataFrame.\n@asset\ndef raw_owid_co2_data() -&gt; pd.DataFrame:\n    co2_owid_url = \"https://raw.githubusercontent.com/owid/co2-data/master/owid-co2-data.csv\"\n    return df.read_csv(co2_owid_url)\nThis will make a new asset appear in the Dagster UI (available at localhost:3000 after running make dev). You can now select it and click “Materialize selected” to run the function and save the resulting DataFrame to our local DuckDB database.\nOnce the asset is materialized, you can start querying it.\n&gt;&gt;&gt; from datadex.utils import query\n&gt;&gt;&gt; query(\"select count(*) from public.raw_owid_co2_data\")\n   count_star()\n0         50598\n\n\n\nOnce the data is available in the local DuckDB database, you can start modeling it. You can continue using Dagster or switch to dbt. Let’s explore the dbt side now.\nWe want to make dbt able to read the dataset Dagster materialized. To do that, we need to add a new table source to the sources.yml:\nversion: 2\nsources:\n  - name: public\n      - name: raw_owid_co2_data\n        meta:\n          dagster:\n            asset_key: [\"raw_owid_co2_data\"]\nNow we can create our SQL models referencing the source we just created. This is a simple query on climate_owid_co2_by_country.sql:\nselect country, iso_code, year, co2 from {{ source(\"public\", \"raw_owid_co2_data\") }}\nTo run this model, we need to refresh the Dagster definitions on Reload definitions and materialize the new dbt node. That will kick off a dbt run and materialize the resulting table as parquet files (due to the external materialization in the dbt_project.yml configuration).\n\n\n\nFinally, we can use the data in a notebook. Let’s say we want to plot the CO2 emissions for a given country. We can use the climate_owid_co2_by_country table we just created:\nfrom datadex.utils import query\n\ndf = query(\"select * from climate_owid_co2_by_country where country = 'World'\")\n_ = df.plot(x=\"year\", y=\"co2\", kind=\"line\")\nThat will plot the CO2 emissions for the whole world!"
  },
  {
    "objectID": "docs/tutorial.html#adding-data-sources",
    "href": "docs/tutorial.html#adding-data-sources",
    "title": "Datadex Tutorial",
    "section": "",
    "text": "The first thing is to add your desired dataset to Datadex. To do that, you’ll need to create a new Dagster Asset in assets.py. You’ll need to write a Python function that returns a DataFrame. You can do anything and read from anywhere as long as you return a DataFrame.\n@asset\ndef raw_owid_co2_data() -&gt; pd.DataFrame:\n    co2_owid_url = \"https://raw.githubusercontent.com/owid/co2-data/master/owid-co2-data.csv\"\n    return df.read_csv(co2_owid_url)\nThis will make a new asset appear in the Dagster UI (available at localhost:3000 after running make dev). You can now select it and click “Materialize selected” to run the function and save the resulting DataFrame to our local DuckDB database.\nOnce the asset is materialized, you can start querying it.\n&gt;&gt;&gt; from datadex.utils import query\n&gt;&gt;&gt; query(\"select count(*) from public.raw_owid_co2_data\")\n   count_star()\n0         50598"
  },
  {
    "objectID": "docs/tutorial.html#modeling-data",
    "href": "docs/tutorial.html#modeling-data",
    "title": "Datadex Tutorial",
    "section": "",
    "text": "Once the data is available in the local DuckDB database, you can start modeling it. You can continue using Dagster or switch to dbt. Let’s explore the dbt side now.\nWe want to make dbt able to read the dataset Dagster materialized. To do that, we need to add a new table source to the sources.yml:\nversion: 2\nsources:\n  - name: public\n      - name: raw_owid_co2_data\n        meta:\n          dagster:\n            asset_key: [\"raw_owid_co2_data\"]\nNow we can create our SQL models referencing the source we just created. This is a simple query on climate_owid_co2_by_country.sql:\nselect country, iso_code, year, co2 from {{ source(\"public\", \"raw_owid_co2_data\") }}\nTo run this model, we need to refresh the Dagster definitions on Reload definitions and materialize the new dbt node. That will kick off a dbt run and materialize the resulting table as parquet files (due to the external materialization in the dbt_project.yml configuration)."
  },
  {
    "objectID": "docs/tutorial.html#using-data",
    "href": "docs/tutorial.html#using-data",
    "title": "Datadex Tutorial",
    "section": "",
    "text": "Finally, we can use the data in a notebook. Let’s say we want to plot the CO2 emissions for a given country. We can use the climate_owid_co2_by_country table we just created:\nfrom datadex.utils import query\n\ndf = query(\"select * from climate_owid_co2_by_country where country = 'World'\")\n_ = df.plot(x=\"year\", y=\"co2\", kind=\"line\")\nThat will plot the CO2 emissions for the whole world!"
  },
  {
    "objectID": "notebooks/2023-01-01-Datadex.html",
    "href": "notebooks/2023-01-01-Datadex.html",
    "title": "Example Report",
    "section": "",
    "text": "Reports are a great way to share your work with others. Thanks to Quarto and Datadex, you can create beautiful reports with a few lines of code and share them with the world. Let’s go through a few interesting things we can do.\nStarting with the most basic thing, we can display Pandas DataFrames as tables.\n\n\nCode\nfrom IPython.display import Markdown\nfrom tabulate import tabulate\n\ntable = [\n    [\"Sun\", 696000, 1989100000],\n    [\"Earth\", 6371, 5973.6],\n    [\"Moon\", 1737, 73.5],\n    [\"Mars\", 3390, 641.85],\n]\nMarkdown(tabulate(table, headers=[\"Planet\", \"R (km)\", \"mass (x 10^29 kg)\"]))\n\n\n\n\nTable 1: Planets\n\n\n\n\n\n\nPlanet\nR (km)\nmass (x 10^29 kg)\n\n\n\n\nSun\n696000\n1.9891e+09\n\n\nEarth\n6371\n5973.6\n\n\nMoon\n1737\n73.5\n\n\nMars\n3390\n641.85\n\n\n\n\n\n\n\n\nAnd, of course, plotting arbitrary data is easy.\n\nCode\nimport matplotlib.pyplot as plt\n\nplt.plot([1, 23, 2, 4])\nplt.show()\n\nplt.plot([8, 65, 23, 90])\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) First\n\n\n\n\n\n\n\n\n\n\n\n(b) Second\n\n\n\n\n\n\n\nFigure 1: Charts\n\n\n\nWe can improve the graphs making them dynamic!\n\n\nCode\nimport altair as alt\nimport numpy as np\nimport pandas as pd\n\nalt.themes.enable(\"vox\")\n\nnp.random.seed(42)\nsource = pd.DataFrame(\n    np.cumsum(np.random.randn(100, 3), 0).round(2),\n    columns=[\"A\", \"B\", \"C\"],\n    index=pd.RangeIndex(100, name=\"x\"),\n)\nsource = source.reset_index().melt(\"x\", var_name=\"category\", value_name=\"y\")\n\n# Create a selection that chooses the nearest point & selects based on x-value\nnearest = alt.selection_point(nearest=True, on=\"mouseover\", fields=[\"x\"], empty=False)\n\n# The basic line\nline = (\n    alt.Chart(source)\n    .mark_line(interpolate=\"basis\")\n    .encode(x=\"x:Q\", y=\"y:Q\", color=\"category:N\")\n)\n\n# Transparent selectors across the chart. This is what tells us\n# the x-value of the cursor\nselectors = (\n    alt.Chart(source)\n    .mark_point()\n    .encode(\n        x=\"x:Q\",\n        opacity=alt.value(0),\n    )\n    .add_params(nearest)\n)\n\n# Draw points on the line, and highlight based on selection\npoints = line.mark_point().encode(\n    opacity=alt.condition(nearest, alt.value(1), alt.value(0))\n)\n\n# Draw text labels near the points, and highlight based on selection\ntext = line.mark_text(align=\"left\", dx=5, dy=-5).encode(\n    text=alt.condition(nearest, \"y:Q\", alt.value(\" \"))\n)\n\n# Draw a rule at the location of the selection\nrules = (\n    alt.Chart(source)\n    .mark_rule(color=\"gray\")\n    .encode(\n        x=\"x:Q\",\n    )\n    .transform_filter(nearest)\n)\n\n# Put the five layers into a chart and bind the data\nalt.layer(line, selectors, points, rules, text).properties(\n    width=\"container\", height=400\n)\n\n\n\n\n\n\n\n\nSince we’re in the Datadex environment, we can access the dbt models in out local DuckDB database.\n\n\nCode\nfrom datadex.utils import query\n\ndf = query(\"from climate_co2_global_trend\")\n\nc = (\n    alt.Chart(df)\n    .mark_line()\n    .encode(\n        x=alt.X(\"date:T\", title=\"Date\"),\n        y=alt.Y(\"trend:Q\", scale=alt.Scale(domain=[390, 430]), title=\"CO2 (ppm)\"),\n        tooltip=[\n            alt.Tooltip(\"date:T\", title=\"Date\"),\n            alt.Tooltip(\"trend:Q\", title=\"CO2 (ppm)\"),\n        ],\n    )\n    .properties(width=\"container\", height=400)\n)\n\nc.display()"
  },
  {
    "objectID": "notebooks/index.html",
    "href": "notebooks/index.html",
    "title": "Notebooks",
    "section": "",
    "text": "Dashboard\n\n\n\n\n\nExample Dashboard. This is a dashboard that uses DuckDB WASM to run queries from your browser.\n\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nExample Report\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2023\n\n\nDavid Gasquez\n\n\n\n\n\n\n\n\n\n\n\n\nObservable Notebooks\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2023\n\n\nDavid Gasquez\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "README.html",
    "href": "README.html",
    "title": "\nD A T A D E X\n",
    "section": "",
    "text": "Collaborate on Open Data using Open Source Tools\nOpen source, serverless, and local-first Data Platform to collaborate on Open Data! Built on top of Dagster, dbt, Quarto, DuckDB, and Evidence.\nThis repository is an up to date toy implementation of the overall pattern. You can check two real world production instances of Datadex working in the following repositories:"
  },
  {
    "objectID": "README.html#setup",
    "href": "README.html#setup",
    "title": "\nD A T A D E X\n",
    "section": "⚙️ Setup",
    "text": "⚙️ Setup\nDatadex consists of several components and requires some setup to get started.\n\n🐳 Docker / Dev Containers\nThe fastest way to start using Datadex is via VSCode Remote Containers. Once inside the develpment environment, you’ll only need to run make dev to spin up the Dagster UI locally.\n\nThe development environment can also run in your browser thanks to GitHub Codespaces!\nYou can also build the Dockerfile image locally and run it with:\ndocker build -t datadex .\ndocker run -it -v $(pwd):/workspaces/datadex -p 3000:3000 datadex\n\n\n🐍 Python Virtual Environment\nClone the repository and run the following commands from the root folder:\n# Create a virtual environment\npython3 -m venv .venv\nsource .venv/bin/activate\n\n# Install the package and dependencies\npip install -e .[dev]\nNow, you should be able to spin up Dagster UI and access it locally."
  },
  {
    "objectID": "README.html#motivation",
    "href": "README.html#motivation",
    "title": "\nD A T A D E X\n",
    "section": "🎯 Motivation",
    "text": "🎯 Motivation\nThis project started after thinking how an Open Data Protocol could look like!"
  },
  {
    "objectID": "README.html#acknowledgements",
    "href": "README.html#acknowledgements",
    "title": "\nD A T A D E X\n",
    "section": "👏 Acknowledgements",
    "text": "👏 Acknowledgements\n\nThis proof of concept was created thanks to open source projects like DuckDB, dbt, Dagster, and Quarto.\nDatadex name was inspired by Juan Benet’s data projects."
  },
  {
    "objectID": "notebooks/2023-11-01-Observable.html",
    "href": "notebooks/2023-11-01-Observable.html",
    "title": "Observable Notebooks",
    "section": "",
    "text": "Quarto is able to run Observable Notebooks. Observable is able to run DuckDB in the browser.\nLet’s showcase it!\nenergydb = DuckDBClient.of({\n  energy: FileAttachment(\"https://raw.githubusercontent.com/datonic/spain-energy-demand/main/data/spain-energy-demand.csv\")\n})\nInputs.table(energydb.query(\"select * from energy order by datetime desc limit 10\"))\nmonthly = energydb.sql`select date_part('month', datetime) as t, avg(value) / 1000 as v from energy group by 1 order by 1 desc`\n\nPlot.plot({\n  grid: true,\n  marks: [\n    Plot.lineY(monthly, {\n      x: \"t\",\n      y: \"v\"\n    }),\n    ]\n})\nVoila!"
  },
  {
    "objectID": "notebooks/2023-11-01-Observable.html#plotting-10-million-flights",
    "href": "notebooks/2023-11-01-Observable.html#plotting-10-million-flights",
    "title": "Observable Notebooks",
    "section": "Plotting 10 Million Flights",
    "text": "Plotting 10 Million Flights\n\nvg = {\n  const vg = await import('https://cdn.jsdelivr.net/npm/@uwdata/vgplot/+esm');\n  const wasm = await vg.wasmConnector();\n  vg.coordinator().databaseConnector(wasm);\n  return vg;\n}\n\nviewof flights = {\n  // load flights data from external parquet file\n  await vg.coordinator().exec(`CREATE TABLE IF NOT EXISTS flights10m AS\n    SELECT\n      GREATEST(-60, LEAST(ARR_DELAY, 180))::DOUBLE AS delay,\n      DISTANCE AS distance,\n      DEP_TIME AS time\n    FROM 'https://uwdata.github.io/mosaic-datasets/data/flights-10m.parquet'`);\n\n  // create a selection with crossfilter resolution\n  const brush = vg.Selection.crossfilter();\n\n  // helper method to generate a binned plot filtered by brush\n  // a plot contains a rectY mark for a histogram, as well as\n  // an intervalX interactor to populate the brush selection\n  const makePlot = column =&gt; vg.plot(\n    vg.rectY(\n      vg.from(\"flights10m\", { filterBy: brush }), // data set and filter selection\n      { x: vg.bin(column), y: vg.count(), fill: \"steelblue\", inset: 0.5 }\n    ),\n    vg.intervalX({ as: brush }), // create an interval selection brush\n    vg.xDomain(vg.Fixed), // don't change the x-axis domain across updates\n    vg.marginLeft(75),\n    vg.width(600),\n    vg.height(200)\n  );\n\n  // generate dashboard with three linked histograms\n  return vg.vconcat(\n    makePlot(\"delay\"),\n    makePlot(\"time\"),\n    makePlot(\"distance\")\n  );\n}"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\nD A T A D E X\n",
    "section": "",
    "text": "Collaborate on Open Data using Open Source Tools\nOpen source, serverless, and local-first Data Platform to collaborate on Open Data! Built on top of Dagster, dbt, Quarto, DuckDB, and Evidence.\nThis repository is an up to date toy implementation of the overall pattern. You can check two real world production instances of Datadex working in the following repositories:"
  },
  {
    "objectID": "index.html#setup",
    "href": "index.html#setup",
    "title": "\nD A T A D E X\n",
    "section": "⚙️ Setup",
    "text": "⚙️ Setup\nDatadex consists of several components and requires some setup to get started.\n\n🐳 Docker / Dev Containers\nThe fastest way to start using Datadex is via VSCode Remote Containers. Once inside the develpment environment, you’ll only need to run make dev to spin up the Dagster UI locally.\n\nThe development environment can also run in your browser thanks to GitHub Codespaces!\nYou can also build the Dockerfile image locally and run it with:\ndocker build -t datadex .\ndocker run -it -v $(pwd):/workspaces/datadex -p 3000:3000 datadex\n\n\n🐍 Python Virtual Environment\nClone the repository and run the following commands from the root folder:\n# Create a virtual environment\npython3 -m venv .venv\nsource .venv/bin/activate\n\n# Install the package and dependencies\npip install -e .[dev]\nNow, you should be able to spin up Dagster UI and access it locally."
  },
  {
    "objectID": "index.html#motivation",
    "href": "index.html#motivation",
    "title": "\nD A T A D E X\n",
    "section": "🎯 Motivation",
    "text": "🎯 Motivation\nThis project started after thinking how an Open Data Protocol could look like!"
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "\nD A T A D E X\n",
    "section": "👏 Acknowledgements",
    "text": "👏 Acknowledgements\n\nThis proof of concept was created thanks to open source projects like DuckDB, dbt, Dagster, and Quarto.\nDatadex name was inspired by Juan Benet’s data projects."
  }
]